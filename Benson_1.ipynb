{
 "metadata": {
  "name": "",
  "signature": "sha256:b1bc67058aae3625f95baf238604feb809a666af1023118c6b8fb1d9e9ef5f1a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Download the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import mta\n",
      "\n",
      "mta.get_turnstile_data(num_files=14,\n",
      "                       data_url=\"http://web.mta.info/developers/turnstile.html\",\n",
      "                       destination='./data/')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Downloading turnstile key from http://web.mta.info/developers/resources/nyct/turnstile/Remote-Booth-Station.xls\n",
        "Downloading 1 of 14: http://web.mta.info/developers/data/nyct/turnstile/turnstile_140830.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Downloading 2 of 14: http://web.mta.info/developers/data/nyct/turnstile/turnstile_140823.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Downloading 3 of 14: http://web.mta.info/developers/data/nyct/turnstile/turnstile_140816.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Downloading 4 of 14: http://web.mta.info/developers/data/nyct/turnstile/turnstile_140809.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Downloading 5 of 14: http://web.mta.info/developers/data/nyct/turnstile/turnstile_140802.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Downloading 6 of 14: http://web.mta.info/developers/data/nyct/turnstile/turnstile_140726.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Downloading 7 of 14: http://web.mta.info/developers/data/nyct/turnstile/turnstile_140719.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Downloading 8 of 14: http://web.mta.info/developers/data/nyct/turnstile/turnstile_140712.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Downloading 9 of 14: http://web.mta.info/developers/data/nyct/turnstile/turnstile_140705.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Downloading 10 of 14: http://web.mta.info/developers/data/nyct/turnstile/turnstile_140628.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Downloading 11 of 14: http://web.mta.info/developers/data/nyct/turnstile/turnstile_140621.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Downloading 12 of 14: http://web.mta.info/developers/data/nyct/turnstile/turnstile_140614.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Downloading 13 of 14: http://web.mta.info/developers/data/nyct/turnstile/turnstile_140607.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Downloading 14 of 14: http://web.mta.info/developers/data/nyct/turnstile/turnstile_140531.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pwd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "u'/Users/gabrielgluck/Projects/dsbc-nyc2014/project-benson'"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Benson_1.ipynb  README.md       \u001b[34mdata\u001b[m\u001b[m/           mta.py          mta.pyc\r\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load mta.py\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "import glob\n",
      "import codecs\n",
      "import random\n",
      "\n",
      "\n",
      "from bs4 import BeautifulSoup\n",
      "import pandas\n",
      "import urllib2\n",
      "import re\n",
      "\n",
      "from collections import defaultdict\n",
      "from pprint import pprint\n",
      "from datetime import datetime\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.dates as mdates\n",
      "\n",
      "\n",
      "DATA_DIRECTORY = \"data/\"\n",
      "FILENAME_FORMAT = DATA_DIRECTORY + \"turnstile_??????.txt\"\n",
      "EXTREME_COUNT_LIMIT = 1e6\n",
      "\n",
      "\n",
      "def download(file_url, destination=None, filename=None):\n",
      "\n",
      "    if destination is None:\n",
      "        destination = '.'\n",
      "    page = urllib2.urlopen(file_url)\n",
      "    if filename is None: \n",
      "        filename = destination + '/' + file_url.split('/')[-1]\n",
      "    local = open(filename, 'w')\n",
      "    local.write(page.read())\n",
      "    local.close()\n",
      "\n",
      "\n",
      "def xls_to_csv(xls_filename, csv_filename = None, delimiter=None):\n",
      "\n",
      "    xls =  pandas.ExcelFile(xls_filename)\n",
      "    sheet = xls.sheet_names[0]\n",
      "    data_frame = xls.parse(sheet)\n",
      "    if csv_filename is None:\n",
      "        csv_filename = xls_filename.rsplit('.xls',1)[0] + '.csv'\n",
      "    if delimiter is None:\n",
      "        delimiter = ','\n",
      "    data_frame.to_csv(csv_filename, index=False, sep=delimiter)\n",
      "\n",
      "\n",
      "def get_turnstile_data(num_files=None,\n",
      "                       data_url=\"http://web.mta.info/developers/turnstile.html\",\n",
      "                       destination = None):\n",
      "\n",
      "    # connect\n",
      "    page  = urllib2.urlopen(data_url)\n",
      "    soup = BeautifulSoup(page)\n",
      "    base_url = data_url.strip('/').rsplit('/',1)[0]\n",
      "\n",
      "    # get the turnstile key file\n",
      "    turnstile_key_text = soup.find(text=re.compile(\"Remote Unit/Control Area/Station Name Key\"))\n",
      "    turnstile_key_file_url = base_url + '/' + turnstile_key_text.parent['href']\n",
      "    print \"Downloading turnstile key from %s\" % turnstile_key_file_url\n",
      "    download(turnstile_key_file_url, destination=destination, filename='turnstile_key.xls')\n",
      "    xls_to_csv('turnstile_key.xls', 'turnstile_key.csv')\n",
      "\n",
      "    # get the turnstile data files\n",
      "    data_h2 = soup.find(text=re.compile(\"Data Files\"))\n",
      "    data_div = data_h2.parent.parent\n",
      "    data_file_links = data_div.find_all(\"a\")\n",
      "    if num_files is not None:\n",
      "        data_file_links = data_file_links[:num_files]\n",
      "    total_file_num = len(data_file_links)\n",
      "    for current_file_num, link in enumerate(data_file_links):\n",
      "        data_file_url = base_url + '/' + link['href']\n",
      "        print 'Downloading %i of %i: %s' % (current_file_num+1, \n",
      "                                            total_file_num,\n",
      "                                            data_file_url)\n",
      "        download(data_file_url, destination=destination)\n",
      "    print 'Done.'\n",
      "\n",
      "\n",
      "def get_glob(file_format=FILENAME_FORMAT):\n",
      "    filenames = glob.glob(file_format)\n",
      "    return filenames\n",
      "\n",
      "def extract_turnstile_data_from_csvs(filenames):\n",
      "    ts = defaultdict(list)\n",
      "    for filename in filenames:\n",
      "        with open(filename,'r') as infile:\n",
      "            print 'extracting ',filename\n",
      "            reader = csv.reader(infile)\n",
      "\n",
      "            for line in reader:\n",
      "                b,r,t = line[:3]\n",
      "                entries = line[3:]\n",
      "                ts[(b,r,t)].extend(entries)\n",
      "    return ts\n",
      "\n",
      "def get_ts_counts_fastawesome(ts):\n",
      "    turnstile_counts = defaultdict(list)\n",
      "    print 'calculating turnstile counts for %d turnstiles.'%len(ts.items())\n",
      "\n",
      "    for turnstile,tlist in ts.iteritems():\n",
      "        \n",
      "        tlist = np.array(tlist).reshape(len(tlist)/5,5)\n",
      "        days = sorted(list(set(tlist[:,0])))\n",
      "\n",
      "        bookmark = 0\n",
      "        for day in days:\n",
      "            day_rows = np.array([tlist[bookmark]])\n",
      "            entries = [int(tlist[bookmark][3])]\n",
      "            while tlist[bookmark][0]==day and bookmark<tlist.shape[0]-1:\n",
      "                #print bookmark,tlist[bookmark]\n",
      "                bookmark += 1\n",
      "                if tlist[bookmark][2]=='REGULAR':\n",
      "                    day_rows = np.vstack((day_rows,tlist[bookmark]))\n",
      "                    entries.append(int(tlist[bookmark][3]))\n",
      "            entries = np.array(entries)\n",
      "\n",
      "            diffs = np.diff(entries)\n",
      "            day_count = sum(diffs[np.where((diffs>=0)&(diffs<10000))])\n",
      "            date = datetime.strptime(day,'%m-%d-%y')\n",
      "\n",
      "            turnstile_counts[turnstile].append((date,day_count))\n",
      "            if day_count>20000: \n",
      "               print 'REALLY BIG!'\n",
      "               print day \n",
      "               print entries\n",
      "               print diffs\n",
      "               print sum(diffs),np.max(entries)-np.min(entries),sum(diffs[np.where(diffs>=0)])\n",
      "\n",
      "    return turnstile_counts\n",
      "\n",
      "\n",
      "def collapse_data_to_booth_remote(turnstile_counts,stop_after=0):\n",
      "    '''\n",
      "    original data is listed by turnstile\n",
      "    collapses and sums all turnstiles for each booth-remote \n",
      "    '''\n",
      "    br_data_dict = defaultdict(list)\n",
      "    # reduce to new indexes using only booth and remote, and put all the [date,counts] from the\n",
      "    # different turnstiles in one big list\n",
      "    for turnstile in turnstile_counts.iteritems():\n",
      "        (b,r,t),counts = turnstile\n",
      "        br_data_dict[(b,r)].extend(counts)\n",
      "\n",
      "    # take each big list and sum up the counts for each date\n",
      "    brcount = 1\n",
      "    collapsed_dict = defaultdict(list)\n",
      "    for br,c in br_data_dict.iteritems():\n",
      "        brcount += 1\n",
      "        collapsed = [[date,sum([tcount for d,tcount in c if d==date])] for date in set([date for date,count in c])]    \n",
      "        #br_data_dict[br] = sorted(collapsed)\n",
      "        collapsed_dict[br] = sorted(collapsed)    \n",
      "        if brcount == stop_after: break\n",
      "            \n",
      "    return br_data_dict,collapsed_dict\n",
      "\n",
      "\n",
      "def dates_and_counts(br_counts):\n",
      "    dates,counts = ([d for d,c in br_counts],[c for d,c in br_counts])\n",
      "    return dates,counts\n",
      "\n",
      "\n",
      "def read_turnstile_data_from_filenames(filenames,verbose=False):\n",
      "    \"\"\" given a glob (filename pattern with wildcards), this reads all the files \"\"\"\n",
      "\n",
      "    turnstile_data = defaultdict(list)    \n",
      "    for filename in filenames:\n",
      "        turnstile_data = add_week_to_data(turnstile_data, filename, stop_after=0,verbose=verbose)\n",
      "    \n",
      "    turnstile_data = remove_trailing_counts(turnstile_data)\n",
      "    #turnstile_data = check_for_gnarly_data(turnstile_data)\n",
      "    \n",
      "    return turnstile_data\n",
      "\n",
      "\n",
      "def convert_datestring_to_datetime(datestring_list):\n",
      "    converted_list = []\n",
      "    for datestr in datestring_list:\n",
      "        date = datetime.strptime(datestr,'%m-%d-%y')\n",
      "        converted_list.append(date)\n",
      "    return converted_list\n",
      "\n",
      "\n",
      "def plot_boothremote(boothremote):\n",
      "    br_id,br_dates,br_counts = parse_boothremote(boothremote)\n",
      "    p = plt.plot(br_dates,br_counts)\n",
      "    return\n",
      "\n",
      "def plot_boothremote_weekly(boothremote):\n",
      "    br_id,dates,counts = parse_boothremote(boothremote)\n",
      "    counts_by_week = shape_counts_to_weeks(counts)\n",
      "\n",
      "    for week in counts_by_week:\n",
      "        plt.plot(week)\n",
      "    xl = plt.xlabel('Day of the week')\n",
      "    yl = plt.ylabel('Number of turnstile entries')\n",
      "    xt = plt.xticks(np.arange(7),['S','S','M','T','W','R','F'])    \n",
      "    \n",
      "def shape_counts_to_weeks(counts):\n",
      "    # trim data down to even weeks\n",
      "    flat_counts = counts[:]\n",
      "    while len(flat_counts)%7:\n",
      "        flat_counts.pop()\n",
      "    flat_counts = np.array(flat_counts)\n",
      "\n",
      "    counts_by_week = flat_counts.reshape(len(flat_counts)/7,7)\n",
      "    return counts_by_week\n",
      "\n",
      "def reshape_flat_counts_to_weekly(counts):\n",
      "    # first let's trim this down to an even number of weeks so we can have a rectangle \n",
      "    flat_counts = counts[:]\n",
      "    while len(flat_counts)%7:\n",
      "        flat_counts.pop()\n",
      "    # now convert it to a numpy array\n",
      "    flat_counts = np.array(flat_counts)\n",
      "\n",
      "    #reshape it into a rectangle 7 columns wide with a row for each week you have\n",
      "    counts_by_week = flat_counts.reshape(len(flat_counts)/7,7)\n",
      "    return counts_by_week\n",
      "\n",
      "\n",
      "def parse_boothremote(boothremote):\n",
      "    br_id,br_datecounts = boothremote\n",
      "    \n",
      "    dates = [d for d,c in br_datecounts]\n",
      "    if type(dates[0])==type('a'):\n",
      "        dates = convert_datestring_to_datetime(dates)\n",
      "    counts = [c for d,c in br_datecounts]\n",
      "    return br_id,dates,counts\n",
      "\n",
      "\n",
      "def create_booth_remote_station_key(filename):\n",
      "\n",
      "    booth_remote_to_station = {}\n",
      "    with open(filename,'r') as infile:\n",
      "        reader = csv.reader(infile)\n",
      "        for line in reader:\n",
      "            remote, booth, station, lines, div = line\n",
      "            if remote == 'Remote': continue\n",
      "            br = (booth, remote)\n",
      "            # yell out if there are any duplicates                                                                                                                                   \n",
      "            if br in booth_remote_to_station:\n",
      "                print 'WARNING, MULTIPLE STATIONS FOR BOOTH-REMOTE %s' % br\n",
      "            booth_remote_to_station[br] = station\n",
      "\n",
      "    return booth_remote_to_station\n",
      "\n",
      "def plot_weeks(br,station_name):\n",
      "    br_id = br[0]\n",
      "    dates,counts = dates_and_counts(br[1])\n",
      "    for week in reshape_flat_counts_to_weekly(counts):\n",
      "        plt.plot(week)\n",
      "    \n",
      "    xl = plt.xlabel('Day of the week')\n",
      "    yl = plt.ylabel('Number of turnstile entries')\n",
      "    xt = plt.xticks(np.arange(7),['S','S','M','T','W','R','F'])\n",
      "    tt = plt.title('Ridership per day for station %s'%station_name)\n",
      "    return\n",
      "\n",
      "def get_a_random_boothremote(boothremotes):\n",
      "    br = random.sample(boothremotes.items(),1)\n",
      "    # random.sample gives us a list and we just want the item in that list\n",
      "    return br[0]\n",
      "\n",
      "def plot_timeseries_and_weeklies(br,station_key):\n",
      "    f = plt.figure(figsize=(16,4)) \n",
      "    plt.subplot(121)\n",
      "    plot_boothremote(br)\n",
      "    tt = plt.title(station_key[br[0]])\n",
      "    plt.subplot(122)\n",
      "    plot_boothremote_weekly(br)\n",
      "    tt = plt.title(station_key[br[0]])\n",
      "    return\n",
      "\n",
      "\n",
      "# def convert_datetime_in_time_series_collection(time_series_collection):\n",
      "#     \"\"\" converts date strings to datetime objects.\n",
      "#         assumes the time series collection format of:\n",
      "#         {id: [(date_str, value), ... ]} \n",
      "#     \"\"\"\n",
      "#     converted_collection = {}\n",
      "#     for _id, time_series in time_series_collection.items():\n",
      "#         converted_time_series = []\n",
      "#         for date_str, value in time_series:\n",
      "#             date = datetime.strptime(date_str, '%m-%d-%y')\n",
      "#             converted_time_series.append( (date, value) )\n",
      "#         converted_collection[_id] = converted_time_series\n",
      "#     return converted_collection\n",
      "\n",
      "# def convert_time_series_into_x_and_y(time_series):\n",
      "#     \"\"\" takes a list of tuples [(time, value), ...]\n",
      "#         and returns two lists of same length,\n",
      "#         one for the times, the other for values\n",
      "#     \"\"\"\n",
      "#     days, values = [], []\n",
      "#     for day, value in time_series:\n",
      "#         days.append(day)\n",
      "#         values.append(value)\n",
      "#     return days, values\n",
      "\n",
      "\n",
      "# def add_week_to_data(data_dict, filename, stop_after=100, verbose=True):\n",
      "#     ''' don't use this one'''\n",
      "#     #use stop_after = 0 to not stop                                                                                                                                                  \n",
      "#     counter = 1\n",
      "#     faulty_data_counter = 0\n",
      "\n",
      "#     with open(filename,'r') as infile:\n",
      "#         reader = csv.reader(infile)\n",
      "#         for line in reader:\n",
      "#             counter += 1\n",
      "#             booth,remote,turnstile = line[:3]\n",
      "\n",
      "#             for i in range(4,len(line),5):\n",
      "#                 irr = False\n",
      "#                 if line[i]=='00:00:00':\n",
      "#                     #print line[i-1:i+4]\n",
      "                                                                                                                              \n",
      "#                     date,time,regular,today_cumulative,exits = line[i-1:i+4]\n",
      "#                     if regular != 'REGULAR':\n",
      "#                         irr = True\n",
      "#                         continue\n",
      "#                     if irr: print 'oops'\n",
      "#                     today_cumulative = int(today_cumulative)\n",
      "\n",
      "#                     # check for a previous entry      \n",
      "                                                                                                                 \n",
      "#                     if data_dict[(booth,remote,turnstile)] != []:\n",
      "#                         yesterday,yesterday_cumulative = data_dict[(booth,remote,turnstile)].pop()\n",
      " \n",
      "#                         yesterdays_count = today_cumulative-yesterday_cumulative\n",
      "#                         #data_dict[(booth,remote,turnstile)].append([yesterday,yesterdays_count])\n",
      "#                         if  0 <= yesterdays_count:\n",
      "#                             data_dict[(booth,remote,turnstile)].append([yesterday,yesterdays_count])\n",
      "#                         else:\n",
      "\n",
      "#                             faulty_data_counter += 1\n",
      " \n",
      "#                     # add the new entry to the dict      \n",
      "                                                                                                               \n",
      "#                     data_dict[(booth,remote,turnstile)].append([date,today_cumulative])\n",
      "#             if counter == stop_after: break\n",
      "\n",
      "#         if verbose:\n",
      "#             print '%i turnstile-days are skipped due to faulty data' % faulty_data_counter\n",
      "\n",
      "#     return data_dict\n",
      "\n",
      "\n",
      "# def remove_trailing_counts(data_dict):\n",
      "#     # remove the last date/entries list from each list (raw cumulative leftovers)                                                                                                    \n",
      "#     for tstile,count_list in data_dict.iteritems():\n",
      "# \tif len(count_list) > 0:\n",
      "#             count_list.pop()\n",
      "#     return data_dict\n",
      "\n",
      "# def get_gnarly_data(data_dict):\n",
      "#     gnarly_dict = defaultdict(list)\n",
      "#     for tstile, count_list in data_dict.iteritems():\n",
      "#         neg_counts = [(d,c) for d,c in count_list if c < 0]\n",
      "#         if neg_counts: gnarly_dict[tstile]=neg_counts\n",
      "\n",
      "#     return gnarly_dict\n",
      "\n",
      "\n",
      "# def collapse_booth_remote_data_to_stations(br_time_series, br_to_station_key):\n",
      "#     \"\"\" Take the {booth-remote : timeseries} data and collapse it to                                                                                                                 \n",
      "#         stations \"\"\"\n",
      "#     station_time_series = {}\n",
      "#     for booth_remote, time_series in br_time_series.iteritems():\n",
      "#         try:\n",
      "#             station = br_to_station_key[booth_remote]\n",
      "#         except KeyError:\n",
      "#             print 'WARNING. Booth %s (remote %s) IS NOT IN STATION KEY. SKIPPING.' % booth_remote\n",
      "#             continue\n",
      "#         if station not in station_time_series:\n",
      "#             station_time_series[station] = time_series\n",
      "#         else:\n",
      "#             # combine the new time series with the existing one                                                                                                                      \n",
      "#             existing_series = station_time_series[station]\n",
      "#             existing_counts = dict(existing_series)\n",
      "#             for date, new_count in time_series:\n",
      "#                 if date in existing_counts:\n",
      "#                     existing_counts[date] += new_count\n",
      "#                 else:\n",
      "#                     existing_counts[date] = new_count\n",
      "#             combined_series = sorted(existing_counts.items())\n",
      "#             station_time_series[station] = combined_series\n",
      "\n",
      "#     return station_time_series\n",
      "\n",
      "\n",
      "# def get_daily_turnstile_counts(ts):\n",
      "#     turnstile_counts = defaultdict(list)\n",
      "#     #print 'this is how many: probably 4542.'\n",
      "#     for turnstile,tlist in ts.iteritems():\n",
      "\n",
      "#         tlist = np.array(tlist).reshape(len(tlist)/5,5)\n",
      "#         #tlist[:,3]=tlist[:,3].astype(int)\n",
      "#         #tlist[:,4]=tlist[:,4].astype(int)    \n",
      "\n",
      "#         days = sorted(list(set(tlist[:,0])))\n",
      "    \n",
      "#         bookmark = 0\n",
      "#         for day in days:\n",
      "#             # # find the indices for all the rows for your day \n",
      "#             # day_inds = np.where(tlist[:,0]==day)\n",
      "#             # # add one more index for the first row from tomorrow if you aren't at the end of the file\n",
      "#             # if np.max(day_inds)+1 < tlist.shape[0]:\n",
      "#             #     day_inds = np.append(day_inds,np.max(day_inds)+1)\n",
      "\n",
      "#             day_rows_raw = [tlist[bookmark]]\n",
      "#             while tlist[book\n",
      "            \n",
      "#             # extract the rows from your indices\n",
      "#             day_rows_raw = tlist[day_inds]\n",
      "#             # get rid of the ones that aren't coded \"REGULAR\"\n",
      "#             day_rows = day_rows_raw[np.where(day_rows_raw[:,2]=='REGULAR')]\n",
      "\n",
      "#             # pull the column with the ticker counts for entries\n",
      "#             day_entries = day_rows[:,3].astype(int)\n",
      "\n",
      "#             # this says, if the ticker number only goes up and never down, the range of the ticker values is your count for the day\n",
      "#             if len(day_entries)>0 and not sum(np.diff(day_entries)<0):\n",
      "#                 day_count = np.max(day_entries)-np.min(day_entries)\n",
      "                \n",
      "#             # otherwise, \n",
      "#             else:\n",
      "#                 # there might not be any REGULAR rows on your day\n",
      "#                 day_count = 0\n",
      "#                 # or you can just sum up the positive increases while ignoring the decreases. I'm not sure yet if this is a terrible idea.\n",
      "#                 if len(day_entries)>0:\n",
      "#                     day_count = sum(np.diff(day_entries)[np.where(np.diff(day_entries)>0)])\n",
      "\n",
      "#             date = datetime.strptime(day,'%m-%d-%y')\n",
      "#             turnstile_counts[turnstile].append((date,day_count))\n",
      "\n",
      "#     return turnstile_counts\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}